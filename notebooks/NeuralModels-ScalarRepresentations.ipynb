{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Models Scalar Representations\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook aims at understanding artificial neural networks from the point of view of biological neurons. Starting from a Spiking Neural Network the goal is to find possible ways of representing encodings in an Artificial Neural Network setup which does not rely in temporal spikes but in atemporal values instead to be used later to find alternative encoding posibilities for use as input in current **Artificial Neuron Network Model** (*ANNM*) technologies without the need to change the entire paradigm.\n",
    "\n",
    "The present document does not intend to be a complete guide to deeply understand neural coding, but as a high level overview of the encoding mechanism and how to encode a physical property into neural values.\n",
    "\n",
    "This work is inspired by the tuning curves of real neurons and the fact that an ensemble of neurons can represent an encoding of an input into a different vector space, being able to create a linear decoder that reconstructs the initial signal.\n",
    "\n",
    "The work presented here inspired mainly by the following books:\n",
    "\n",
    "- Neural Engineering (Eliasmith and Anderson- 2003)\n",
    "- How to Build a Brain (Eliasmith - 2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How neurons encode values\n",
    "\n",
    "I am going to lie now, it is not a big lie but this is not a complete picture of what happens. Nevertheless this description is enough for the present study.\n",
    "\n",
    "To simplify, a neuron can be in one of two states:\n",
    "1. firing\n",
    "2. not firing\n",
    "\n",
    "For a neuron to fire it needs to accumulate enough charge to pass a firing threshold. \n",
    "This threshold is attained by accumulating charge that comes from spikes of neurons connected to the dentrites of the neuron in question (the one we are analyzing).\n",
    "\n",
    "You can see an example for a single neuron in the [Nengo documentation](https://www.nengo.ai/nengo/v3.0.0/examples/basic/single-neuron.html)\n",
    "\n",
    "When a neuron fires it is called a spike, and after has a refractary period in which it can not fire.\n",
    "\n",
    "For the purposes of the current study of the neuron, what we care about more than if it fired or not is the firing frequency, which will represent a physical property in an encoder.\n",
    "\n",
    "\n",
    "\n",
    "Let's start with an example focusing on the encoding of the horizontal position of the (human) eye.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous to creating any  I do spiking network simulations in [Nengo](https://www.nengo.ai/index.html) to understand the behaviour I want to model and be able to compare.\n",
    "\n",
    "For example, a simple unitary encoding function with 50 neurons produce the following tuning curves\n",
    "\n",
    "![Tuning Curves of a Nengo simulation](imgs/tuning-curves-50n.png)\n",
    "\n",
    "And a nengo simulation of the same 50 neuron unitary function encoding gives the following:\n",
    "\n",
    "![Nengo simulation of 50 neurons](imgs/example-nengo-50n.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representations\n",
    "\n",
    "The firing rate will be represented by the output value of the neuron\n",
    "The input current will be represented by the weighted sum of\n",
    "\n",
    "Taking advantage of the fact that **Artificial Neurons** (*ANs*) are not restricted like the biological ones to positive inputs and outputs we can then draw the tuning curves \n",
    "\n",
    "- Output from the neuron is truncated to a maximum of $1$ and a minimum of $-1$ (normalized to 1)\n",
    "- Input to the neuron is truncated to a maximum of $1$ and a minimum of $-1$ (normalized to 1)\n",
    "\n",
    "To make things simpler for the study the curves will be linear functions, truncated if needed (inspired by the relu)\n",
    "\n",
    "$$ y = f(x) = ax + b $$\n",
    "\n",
    "A restriction is that the function MUST intersect  the $x$ axis between $-1$ and $1$\n",
    "\n",
    "TODO actually correct this part when I figure it out correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crazy Ideas \n",
    "\n",
    "Maybe will be a nice idea to evaluate the effect on the input always to be normalized at the value 1?\n",
    "\n",
    "\n",
    "## Questions\n",
    "\n",
    "Will input weights then would need to be normalized ?\n",
    "\n",
    "What happens if I restrict output to $+-1$ ?\n",
    "\n",
    "What happens if I don't restrict it?\n",
    "\n",
    "What happens if I I do as a ReLu unit and the value cuts at zero?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some definitions\n",
    "\n",
    "**Ensemble**: A set of neurons working together to encode (or decode) an input.\n",
    "\n",
    "**Input**: Can represent a:\n",
    " * Scalar\n",
    " * Vector\n",
    " * Function \n",
    " * Vector Field\n",
    " * ...\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "As inspired by the examples in Nengo and the book *How To Build a Brain* the encoding process will only need to define the number of units in the encoder ensemble.\n",
    "\n",
    "The actual tuning curves will be chosen randomly with a creation function.\n",
    "\n",
    "## Decoder \n",
    "\n",
    "A linear decoder is asumed to exist to any encoder in this work (TODO add BIB).\n",
    "\n",
    "The decoder will be found encoding several different inputs (as many as needed) and then solving the matrix finding the minimum error. A decoder network will be created with the necessary weights.\n",
    "\n",
    "\n",
    "## Expected output from the study\n",
    "\n",
    "A study on the results is expected to experimentally find the reconstruction error and compare it with theoretical grounds.\n",
    "\n",
    "I want to compare the encoding and decoding of several different functions, finding errors (different error measures might be needed) for different sizes of ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Most of the work will be based on Tensorflow and Keras\n",
    "\n",
    "Biologically similar simulations will be created with Nengo and outputs added here as needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
